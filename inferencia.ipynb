{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082e5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import normalizate\n",
    "norm = normalizate('datas/exemplo', \"datas/exemplosnormalizados\")\n",
    "norm.preprocess_and_segment_audio('datas/exemplo/exemplo.mp3',\"datas/exemplosnormalizados\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06a0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o modo de inferência do modelo de Wake Word...\n",
      "Número de frames MFCC por amostra: 301\n",
      "Scaler carregado de: scaler.pkl\n",
      "Modelo carregado de: models/wake_word_model.pth\n",
      "\n",
      "Realizando inferência no arquivo: datas/exemplosnormalizados/exemplo_segment_0001.wav\n",
      "Probabilidade da Wake Word: 0.9876\n",
      "Resultado: É a WAKE WORD!\n",
      "\n",
      "Inferência concluída.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from wakeword import WakeWordCNN\n",
    "\n",
    "print(\"Iniciando o modo de inferência do modelo de Wake Word...\")\n",
    "from joblib import load\n",
    "scaler = load(\"scaler.pkl\")\n",
    "SAMPLERATE = 16000\n",
    "SEGMENT_DURATION_SECONDS = 3\n",
    "N_MFCC = 40     \n",
    "N_FFT = 400       \n",
    "HOP_LENGTH = 160  \n",
    "SCALER_LOAD_PATH = \"scaler.pkl\"\n",
    "scaler = load(SCALER_LOAD_PATH)\n",
    "MODEL_LOAD_PATH = \"models/wake_word_model.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_wake_word(audio_filepath, model, mfcc_transform, scaler, segment_duration_seconds, samplerate, device, threshold):\n",
    "    \"\"\"\n",
    "    Realiza a inferência em um arquivo de áudio para detectar a wake word.\n",
    "    \"\"\"\n",
    "    model.eval() # Coloca o modelo em modo de avaliação\n",
    "\n",
    "    # Pré-processa o áudio\n",
    "    mfccs = preprocess_audio_for_inference(audio_filepath, mfcc_transform, scaler, segment_duration_seconds, samplerate)\n",
    "    if mfccs is None:\n",
    "        return None, None # Retorna None se houver erro no pré-processamento\n",
    "\n",
    "    # Adiciona uma dimensão de lote (batch dimension) pois o modelo espera um lote\n",
    "    # mfccs.shape de (1, N_MFCC, NUM_FRAMES_PER_SAMPLE) para (1, 1, N_MFCC, NUM_FRAMES_PER_SAMPLE)\n",
    "    mfccs = mfccs.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad(): # Desativa o cálculo de gradientes para inferência\n",
    "        outputs = model(mfccs)\n",
    "        probability = torch.sigmoid(outputs).item() # Converte logits para probabilidade (0 a 1)\n",
    "\n",
    "    prediction = 1 if probability >= threshold else 0 # 1 para wake word, 0 para não wake word\n",
    "\n",
    "    return prediction, probability\n",
    "\n",
    "\n",
    "def preprocess_audio_for_inference(audio_filepath, mfcc_transform, scaler, segment_duration_seconds, samplerate):\n",
    "    \n",
    "    \"\"\"\n",
    "    Carrega, pré-processa e extrai MFCCs de um único arquivo de áudio para inferência.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(audio_filepath)\n",
    "\n",
    "        # 1. Converte para mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "        # 2. Resample para a taxa de amostragem correta\n",
    "        if sr != samplerate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, samplerate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # 3. Preenche ou corta para a duração esperada\n",
    "        expected_num_samples = int(samplerate * segment_duration_seconds)\n",
    "        if waveform.shape[1] < expected_num_samples:\n",
    "            padding = expected_num_samples - waveform.shape[1]\n",
    "            waveform = F.pad(waveform, (0, padding))\n",
    "        elif waveform.shape[1] > expected_num_samples:\n",
    "            waveform = waveform[:, :expected_num_samples]\n",
    "\n",
    "        # 4. Extrai MFCCs\n",
    "        mfccs = mfcc_transform(waveform)\n",
    "\n",
    "        # 5. Normaliza MFCCs usando o scaler carregado\n",
    "        mfccs_np = mfccs.squeeze(0).numpy()\n",
    "        mfccs_normalized = scaler.transform(mfccs_np.T).T # Transpõe, normaliza, transpõe de volta\n",
    "        mfccs = torch.from_numpy(mfccs_normalized).float().unsqueeze(0) # Adiciona dimensão de lote e canal\n",
    "\n",
    "        return mfccs\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo de áudio não encontrado em '{audio_filepath}'.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro durante o pré-processamento do áudio: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Calcula o número de frames de MFCC por amostra de áudio (DEVE ser o mesmo do treinamento)\n",
    "dummy_waveform = torch.randn(1, int(SAMPLERATE * SEGMENT_DURATION_SECONDS))\n",
    "mfcc_test_transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate=SAMPLERATE, n_mfcc=N_MFCC,\n",
    "    melkwargs={\"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH, \"n_mels\": N_MFCC}\n",
    ")\n",
    "dummy_mfccs = mfcc_test_transform(dummy_waveform)\n",
    "NUM_FRAMES_PER_SAMPLE = dummy_mfccs.shape[2]\n",
    "print(f\"Número de frames MFCC por amostra: {NUM_FRAMES_PER_SAMPLE}\")\n",
    "\n",
    "# 1. Carrega o scaler\n",
    "try:\n",
    "    print(f\"Scaler carregado de: {SCALER_LOAD_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Scaler não encontrado em '{SCALER_LOAD_PATH}'. Certifique-se de ter treinado o modelo e salvo o scaler.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o scaler: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Instancia o modelo e carrega os pesos treinados\n",
    "model = WakeWordCNN(N_MFCC, NUM_FRAMES_PER_SAMPLE).to(DEVICE)\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_LOAD_PATH, map_location=DEVICE))\n",
    "    print(f\"Modelo carregado de: {MODEL_LOAD_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Modelo não encontrado em '{MODEL_LOAD_PATH}'. Certifique-se de ter treinado o modelo.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o modelo: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 3. Inicializa o transformador MFCC (o mesmo usado no Dataset)\n",
    "mfcc_transform_inference = torchaudio.transforms.MFCC(\n",
    "    sample_rate=SAMPLERATE,\n",
    "    n_mfcc=N_MFCC,\n",
    "    melkwargs={\n",
    "        \"n_fft\": N_FFT,\n",
    "        \"hop_length\": HOP_LENGTH,\n",
    "        \"n_mels\": N_MFCC\n",
    "    }\n",
    ")\n",
    "\n",
    "PREDICTION_THRESHOLD = 0.5\n",
    "# --- Teste com um arquivo de áudio ---\n",
    "# ALtere este caminho para o seu arquivo de áudio de teste!\n",
    "# Pode ser um áudio da sua pasta 'positive/' ou 'negative/'\n",
    "TEST_AUDIO_FILE = \"datas/exemplosnormalizados/exemplo_segment_0001.wav\" # <-- ALtere este caminho!\n",
    "# Ou um áudio da sua pasta 'negative_processed/'\n",
    "# TEST_AUDIO_FILE = \"wake_word_dataset/negative_processed/some_negative_audio_segment_0001.wav\"\n",
    "\n",
    "if not os.path.exists(TEST_AUDIO_FILE):\n",
    "    print(f\"\\nAVISO: O arquivo de áudio de teste '{TEST_AUDIO_FILE}' não foi encontrado.\")\n",
    "    print(\"Por favor, altere a variável 'TEST_AUDIO_FILE' no script para um caminho válido.\")\n",
    "    print(\"Você pode usar um dos arquivos que você gravou na pasta 'wake_word_dataset/positive' ou 'wake_word_dataset/negative'.\")\n",
    "else:\n",
    "    print(f\"\\nRealizando inferência no arquivo: {TEST_AUDIO_FILE}\")\n",
    "    prediction, probability = predict_wake_word(\n",
    "        TEST_AUDIO_FILE,\n",
    "        model,\n",
    "        mfcc_transform_inference,\n",
    "        scaler,\n",
    "        SEGMENT_DURATION_SECONDS,\n",
    "        SAMPLERATE,\n",
    "        DEVICE,\n",
    "        PREDICTION_THRESHOLD\n",
    "    )\n",
    "\n",
    "    if prediction is not None:\n",
    "        print(f\"Probabilidade da Wake Word: {probability:.4f}\")\n",
    "        if prediction == 1:\n",
    "            print(\"Resultado: É a WAKE WORD!\")\n",
    "        else:\n",
    "            print(\"Resultado: NÃO é a Wake Word.\")\n",
    "    else:\n",
    "        print(\"Não foi possível realizar a inferência.\")\n",
    "\n",
    "print(\"\\nInferência concluída.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
