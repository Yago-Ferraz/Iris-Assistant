{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e0b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import normalizate\n",
    "\n",
    "norm = normalizate(\"datas/negativa\", \"datas/negativa normalizada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60bb8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizando arquivos de áudio: 100%|██████████| 3747/3747 [08:18<00:00,  7.52arquivo/s]\n"
     ]
    }
   ],
   "source": [
    "norm.normalizar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7579b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "class WakeWordCNN(nn.Module):\n",
    "    def __init__(self, num_mfccs, num_frames_per_sample):\n",
    "        super(WakeWordCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding='same')\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        # Recalcula _to_linear para garantir que seja o mesmo do treinamento\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 1, num_mfccs, num_frames_per_sample)\n",
    "            x = self.pool1(F.relu(self.bn1(self.conv1(dummy_input))))\n",
    "            x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "            x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "            self._to_linear = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71c544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT_DIR = \"datas\" \n",
    "\n",
    "SEGMENT_DURATION_SECONDS = 3\n",
    "\n",
    "\n",
    "SAMPLERATE = 16000\n",
    "\n",
    "N_MFCC = 40     \n",
    "N_FFT = 400       \n",
    "HOP_LENGTH = 160  \n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13bbf424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de frames MFCC por amostra de 3s: 301\n",
      "Carregadas 72 amostras positivas.\n",
      "Carregadas 7487 amostras negativas.\n",
      "Total de amostras no dataset: 7559\n",
      "Ajustando normalizador (scaler) para as MFCCs...\n",
      "Normalizador ajustado.\n",
      "Tamanho do dataset de treino: 6047\n",
      "Tamanho do dataset de validação: 1512\n",
      "Número de workers para DataLoader: 8\n"
     ]
    }
   ],
   "source": [
    "from dataset import WakeWordDataset\n",
    "from joblib import dump\n",
    "\n",
    "dummy_waveform = torch.randn(1, int(SAMPLERATE * SEGMENT_DURATION_SECONDS))\n",
    "mfcc_test_transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate=SAMPLERATE, n_mfcc=N_MFCC,\n",
    "    melkwargs={\"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH, \"n_mels\": N_MFCC}\n",
    ")\n",
    "dummy_mfccs = mfcc_test_transform(dummy_waveform)\n",
    "NUM_FRAMES_PER_SAMPLE = dummy_mfccs.shape[2] \n",
    "\n",
    "print(f\"Número de frames MFCC por amostra de {SEGMENT_DURATION_SECONDS}s: {NUM_FRAMES_PER_SAMPLE}\")\n",
    "\n",
    "# 1. Cria a instância do Dataset\n",
    "dataset = WakeWordDataset(\n",
    "    root_dir=DATASET_ROOT_DIR,\n",
    "    segment_duration_seconds=SEGMENT_DURATION_SECONDS,\n",
    "    samplerate=SAMPLERATE,\n",
    "    n_mfcc=N_MFCC,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH\n",
    ")\n",
    "print(f\"Total de amostras no dataset: {len(dataset)}\")\n",
    "\n",
    "# 2. Ajusta o scaler (normalizador) para as MFCCs\n",
    "\n",
    "dataset.fit_scaler()\n",
    "dump(dataset.scaler, \"scaler.pkl\")\n",
    "\n",
    "# 3. Divide o dataset em treino e validação\n",
    "train_size = int(0.8 * len(dataset)) # 80% para treino\n",
    "val_size = len(dataset) - train_size # 20% para validação\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Tamanho do dataset de treino: {len(train_dataset)}\")\n",
    "print(f\"Tamanho do dataset de validação: {len(val_dataset)}\")\n",
    "\n",
    "# 4. Cria os DataLoaders para iterar sobre os dados em lotes (batches)\n",
    "BATCH_SIZE = 32 # Tamanho do lote\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count() // 2 or 1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count() // 2 or 1)\n",
    "\n",
    "print(f\"Número de workers para DataLoader: {os.cpu_count() // 2 or 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c463cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 6. Instancia o Modelo CNN\n",
    "model = WakeWordCNN(N_MFCC, NUM_FRAMES_PER_SAMPLE).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff82405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, model_save_path):\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Define o modelo para modo de treinamento\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, (mfccs, labels) in enumerate(train_loader):\n",
    "            mfccs = mfccs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zera os gradientes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Passagem para frente\n",
    "            outputs = model(mfccs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Passagem para trás e otimização\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * mfccs.size(0)\n",
    "\n",
    "            # Calcula a acurácia\n",
    "            # Saída do modelo são logits, sigmoid para obter probabilidades\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Treino Loss: {epoch_loss:.4f}, Treino Acurácia: {epoch_accuracy:.4f}\")\n",
    "\n",
    "        # --- Validação ---\n",
    "        model.eval() # Define o modelo para modo de avaliação (desativa dropout, etc.)\n",
    "        val_running_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "        all_val_labels = []\n",
    "        all_val_predictions = []\n",
    "\n",
    "        with torch.no_grad(): # Desativa o cálculo de gradientes para validação\n",
    "            for mfccs, labels in val_loader:\n",
    "                mfccs = mfccs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(mfccs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * mfccs.size(0)\n",
    "\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                val_correct_predictions += (predicted == labels).sum().item()\n",
    "                val_total_samples += labels.size(0)\n",
    "\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_loss = val_running_loss / val_total_samples\n",
    "        val_accuracy = val_correct_predictions / val_total_samples\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Validação Loss: {val_loss:.4f}, Validação Acurácia: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Calcula métricas adicionais de validação\n",
    "        val_precision = precision_score(all_val_labels, all_val_predictions, zero_division=0)\n",
    "        val_recall = recall_score(all_val_labels, all_val_predictions, zero_division=0)\n",
    "        val_f1 = f1_score(all_val_labels, all_val_predictions, zero_division=0)\n",
    "        print(f\"Validação Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "        # Salva o melhor modelo com base na acurácia de validação\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Modelo salvo em '{model_save_path}' com acurácia de validação: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    print(\"\\nTreinamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de714670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Treino Loss: 0.2452, Treino Acurácia: 0.9866\n",
      "Epoch 1/20 - Validação Loss: 0.0318, Validação Acurácia: 0.9934\n",
      "Validação Precision: 0.8000, Recall: 0.3077, F1-Score: 0.4444\n",
      "Modelo salvo em 'models/wake_word_model_2.pth' com acurácia de validação: 0.9934\n",
      "Epoch 2/20 - Treino Loss: 0.0317, Treino Acurácia: 0.9916\n",
      "Epoch 2/20 - Validação Loss: 0.0253, Validação Acurácia: 0.9914\n",
      "Validação Precision: 0.5000, Recall: 0.0769, F1-Score: 0.1333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20 # Número de vezes que o modelo verá todo o dataset\n",
    "BATCH_SIZE = 32\n",
    "num_arquivos = sum(\n",
    "    1 for f in os.listdir('models/') if os.path.isfile(os.path.join('models/', f))\n",
    ") + 1\n",
    "MODEL_SAVE_PATH = f\"models/wake_word_model_{num_arquivos}.pth\"\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 7. Inicia o treinamento\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, DEVICE, MODEL_SAVE_PATH)\n",
    "\n",
    "print(\"\\nTreinamento do modelo de Wake Word concluído e melhor modelo salvo!\")\n",
    "print(f\"O modelo treinado está salvo em: {MODEL_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
